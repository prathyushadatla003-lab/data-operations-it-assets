from elasticsearch import Elasticsearch, helpers
import pandas as pd
import os

# === CONFIGURATION ===
ES_ENDPOINT = "https://my-elasticsearch-project-f8ad9e.es.us-central1.gcp.elastic.cloud:443"
ES_API_KEY = "Rjdtdk01b0JsME1BWlJtRGNUNkc6S0tRN0hKQzRZTTVyRW9mRnNwTWZCdw=="
CSV_FILE = "it_asset_inventory_cleaned.csv"  # e.g., "elastic_exports/my_index.csv"
TARGET_INDEX = "it_asset_inventory_cleaned"

# === CONNECT TO ELASTIC ===
es = Elasticsearch(
    ES_ENDPOINT,
    api_key=ES_API_KEY,
    verify_certs=True
)

# === CHECK CONNECTION ===
if not es.ping():
    print("‚ùå Connection failed! Please check endpoint or API key.")
    exit()
else:
    print("‚úÖ Connected to Elasticsearch!")

# === READ CSV FILE ===
if not os.path.exists(CSV_FILE):
    print(f"‚ùå CSV file not found: {CSV_FILE}")
    exit()

df = pd.read_csv(CSV_FILE)
print(f"üìÑ Loaded {len(df)} records from {CSV_FILE}")

# === PREPARE BULK DATA WITH transaction_id AS _id ===
if 'hostname' not in df.columns:
    print("‚ùå 'hostname' column not found in CSV.")
    exit()

actions = [
    {
        "_index": TARGET_INDEX,
        "_id": str(row['hostname']),  # Set document ID
        "_source": row.to_dict()
    }
    for _, row in df.iterrows()
]

# === BULK UPLOAD ===
try:
    helpers.bulk(es, actions)
    print(f"‚úÖ Successfully uploaded {len(actions)} documents to index '{TARGET_INDEX}' using transaction_id as _id")
except Exception as e:
    print(f"‚ùå Bulk upload failed: {e}")